{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CHECKPOINT = \"microsoft/git-base\"\n",
    "\n",
    "DATASET_ROOT = '../datasets/diffusiondb2m/diffusiondb-filtered/'\n",
    "EVAL_DATASET_ROOT = '../datasets/sampleeval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# DIFFUSIONDB_IMGS_PATH = \"../datasets/diffusiondb2m\"\n",
    "\n",
    "# # # csvs\n",
    "# # csvs = [\"diffusiondb-filtered-0-40000.csv\", \"diffusiondb-filtered-40001-80000.csv\", \"diffusiondb-filtered-80001-120000.csv\", \"diffusiondb-filtered-120001-144894.csv\"]\n",
    "# # dfs = []\n",
    "# # for csv in csvs:\n",
    "# #     df = pd.read_csv(os.path.join(DIFFUSIONDB_IMGS_PATH, csv))\n",
    "# #     dfs.append(df)\n",
    "# # df = pd.concat(dfs)\n",
    "\n",
    "# # df.reset_index(drop=True, inplace=True)\n",
    "# # df.to_csv(os.path.join(DIFFUSIONDB_IMGS_PATH, \"diffusiondb-filtered.csv\"), index=False)\n",
    "\n",
    "# # df = pd.read_csv(os.path.join(DIFFUSIONDB_IMGS_PATH, \"diffusiondb-filtered.csv\"))\n",
    "# # df[\"combined_img_path\"] = df[\"new_image_name\"].apply(lambda x: \"diffusiondb-filtered-combined\"+\"/\"+x.split(\"/\")[1])\n",
    "\n",
    "# # df.reset_index(drop=True, inplace=True)\n",
    "# # df.to_csv(os.path.join(DIFFUSIONDB_IMGS_PATH, \"diffusiondb-filtered-combined.csv\"), index=False)\n",
    "\n",
    "# df = pd.read_csv(os.path.join(DIFFUSIONDB_IMGS_PATH, \"diffusiondb-filtered-combined.csv\"))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions = df[['combined_img_path', 'prompt']].rename(columns={\"combined_img_path\": \"image\", \"prompt\": \"text\"}).to_dict('records')\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(DATASET_ROOT + \"metadata.json\", 'w') as f:\n",
    "#     json.dump(captions, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyyao/miniconda3/envs/samgit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset json (/home/jimmyyao/.cache/huggingface/datasets/json/default-0307859a9943dd22/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "Found cached dataset csv (/home/jimmyyao/.cache/huggingface/datasets/csv/default-4f4e452d0cf0fc80/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "train_ds = load_dataset('json', data_files=DATASET_ROOT + \"metadata.json\", split='train')\n",
    "test_ds = load_dataset('csv', data_files=EVAL_DATASET_ROOT + \"metadata.csv\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(BASE_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def transforms(example_batch, root='../datasets/diffusiondb2m/diffusiondb-filtered/'):\n",
    "    images = [Image.open(os.path.join(root, x)) for x in example_batch[\"image\"]]\n",
    "    captions = [x for x in example_batch[\"text\"]]\n",
    "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
    "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
    "    return inputs\n",
    "\n",
    "train_ds.set_transform(transforms)\n",
    "test_ds.set_transform(lambda b: transforms(b, '../datasets/sampleeval'))\n",
    "# train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "wer = load(\"wer\")\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "st_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predicted = logits.argmax(-1)\n",
    "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
    "    \n",
    "    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    rouge_score = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    clip_score = cos(torch.tensor(st_model.encode(decoded_labels)), torch.tensor(st_model.encode(decoded_predictions))).mean().item()\n",
    "    \n",
    "    return {\"wer_score\": wer_score, \"clip_score\":clip_score, **rouge_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=revsd2\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=revsd2\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_name = BASE_CHECKPOINT.split(\"/\")[1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-revsd2\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=4,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=50,\n",
    "    logging_steps=100,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    "    label_names=[\"labels\"],\n",
    "    # load_best_model_at_end=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"git-base-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyyao/repos/samgit/notebooks/git-base-revsd2 is already a clone of https://huggingface.co/haowjy/git-base-revsd2. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING:huggingface_hub.repository:/home/jimmyyao/repos/samgit/notebooks/git-base-revsd2 is already a clone of https://huggingface.co/haowjy/git-base-revsd2. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping the first batches: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18112' max='13584' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18112/13584 : < :, Epoch 4/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping the first batches: : 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18112, training_loss=0.0, metrics={'train_runtime': 0.0532, 'train_samples_per_second': 8173407.008, 'train_steps_per_second': 255420.732, 'total_flos': 2.7105950323003392e+17, 'train_loss': 0.0, 'epoch': 4.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint='git-base-revsd2/checkpoint-18112')\n",
    "# trainer.train(resume_from_checkpoint='output/GIT/checkpoint-4528')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (36) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (36) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "WARNING:huggingface_hub.repository:The progress bars may be unreliable.\n",
      "batch response: Authorization error.\n",
      "error: failed to push some refs to 'https://user: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@huggingface.co/haowjy/git-base-revsd2'\n",
      "\n",
      "WARNING:huggingface_hub.repository:batch response: Authorization error.\n",
      "error: failed to push some refs to 'https://user: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@huggingface.co/haowjy/git-base-revsd2'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "batch response: Authorization error.\nerror: failed to push some refs to 'https://user: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@huggingface.co/haowjy/git-base-revsd2'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/samgit/lib/python3.9/site-packages/huggingface_hub/repository.py:1099\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[39mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1099\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49msave_model(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutput/GIT/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m-revsd2-\u001b[39;49m\u001b[39m{\u001b[39;49;00mtrainer\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mglobal_step\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/samgit/lib/python3.9/site-packages/transformers/trainer.py:2834\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2832\u001b[0m \u001b[39m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2833\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _internal_call:\n\u001b[0;32m-> 2834\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpush_to_hub(commit_message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mModel save\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/samgit/lib/python3.9/site-packages/transformers/trainer.py:3661\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3658\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress\u001b[39m.\u001b[39m_process\u001b[39m.\u001b[39mkill()\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3661\u001b[0m git_head_commit_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[1;32m   3662\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49mblocking, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   3663\u001b[0m )\n\u001b[1;32m   3664\u001b[0m \u001b[39m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   3665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/miniconda3/envs/samgit/lib/python3.9/site-packages/huggingface_hub/repository.py:1307\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_add(auto_lfs_track\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_push(\n\u001b[1;32m   1308\u001b[0m     upstream\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morigin \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_branch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1309\u001b[0m     blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[1;32m   1310\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39;49mauto_lfs_prune,\n\u001b[1;32m   1311\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/samgit/lib/python3.9/site-packages/huggingface_hub/repository.py:1102\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m blocking:\n\u001b[1;32m   1106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: batch response: Authorization error.\nerror: failed to push some refs to 'https://user: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@huggingface.co/haowjy/git-base-revsd2'\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(f\"output/GIT/{model_name}-revsd2-{trainer.state.global_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samgit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
